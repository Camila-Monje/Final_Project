# Dise√±o de keras, entra todo lo de aumentation y modelo keras


# -*- coding: utf-8 -*-
"""Copia_de_Untitled0_(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BJ3xy1qaGdod8KYQiDXlUciKeFpqOL3F
"""

# 1. INSTALAR DEPENDENCIAS
!pip install albumentations==1.4.3 opencv-python-headless pandas tqdm --quiet

# 2. Descomprimir
import zipfile
import os

zip_path = "/content/strawberryclassification.v1i.tensorflow.zip"
extract_path = "/content/strawberry_dataset"

# Crear carpeta destino y descomprimir
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("‚úÖ Zip descomprimido en:", extract_path)

# 3. AUMENTAR DATASET
# Requiere: pip install albumentations opencv-python-headless pandas
import os
import cv2
import albumentations as A
import pandas as pd
from tqdm import tqdm
from datetime import datetime

# === Par√°metros ===
INPUT_DIR = "/content/strawberry_dataset/train"
CSV_PATH = os.path.join(INPUT_DIR, "_annotations.csv")
OUTPUT_DIR = "/content/augmented"
OUTPUT_CSV = os.path.join(OUTPUT_DIR, "_annotations_augmented.csv")
AUG_PER_IMAGE = 9  # N√∫mero de aumentaciones por imagen

os.makedirs(OUTPUT_DIR, exist_ok=True)

# === Pipeline de aumentaciones ===
augment_pipeline = A.Compose([
    A.OneOf([
        A.HorizontalFlip(p=1.0),
        A.VerticalFlip(p=1.0),
        A.Rotate(limit=90, p=1.0),
        A.RandomBrightnessContrast(p=1.0),
        A.RandomGamma(p=1.0),
        A.RGBShift(p=1.0),
        A.HueSaturationValue(p=1.0)
    ], p=1.0),
    A.RandomSizedBBoxSafeCrop(width=500, height=500, p=0.8)
], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))

# === Leer anotaciones ===
df = pd.read_csv(CSV_PATH)
df['id'] = df.groupby('filename').cumcount()  # Para evitar duplicados si hay m√∫ltiples objetos
grouped = df.groupby("filename")

augmented_rows = []

print("‚è≥ Generando aumentaciones...")

for filename, group in tqdm(grouped):
    image_path = os.path.join(INPUT_DIR, filename)
    image = cv2.imread(image_path)
    if image is None:
        print(f"‚ö†Ô∏è No se pudo leer la imagen: {filename}")
        continue

    bboxes = group[['xmin', 'ymin', 'xmax', 'ymax']].values
    labels = group['class'].tolist()

    for i in range(AUG_PER_IMAGE):
        try:
            aug = augment_pipeline(image=image, bboxes=bboxes, class_labels=labels)
        except Exception as e:
            print(f"‚ùå Error al aumentar {filename}: {e}")
            continue

        new_img = aug['image']
        new_bboxes = aug['bboxes']
        new_labels = aug['class_labels']

        if len(new_bboxes) == 0:
            continue

        timestamp = datetime.now().strftime('%Y%m%d%H%M%S%f')  # Para evitar sobrescrituras
        new_filename = f"{os.path.splitext(filename)[0]}_aug{i}_{timestamp}.jpg"
        new_path = os.path.join(OUTPUT_DIR, new_filename)
        cv2.imwrite(new_path, new_img)

        for j, box in enumerate(new_bboxes):
            x_min, y_min, x_max, y_max = map(int, box)
            augmented_rows.append({
                'filename': new_filename,
                'width': new_img.shape[1],
                'height': new_img.shape[0],
                'class': new_labels[j],
                'xmin': x_min,
                'ymin': y_min,
                'xmax': x_max,
                'ymax': y_max
            })

# === Guardar CSV nuevo ===
augmented_df = pd.DataFrame(augmented_rows)
augmented_df.to_csv(OUTPUT_CSV, index=False)

print(f"‚úÖ Im√°genes aumentadas: {len(augmented_df)} boxes")
print(f"üìÅ Guardado en: {OUTPUT_DIR}")

import os
import cv2
import albumentations as A
import pandas as pd
from tqdm import tqdm

# === Par√°metros ===
INPUT_DIR = "/content/strawberry_dataset/train"
CSV_PATH = os.path.join(INPUT_DIR, "_annotations.csv")
OUTPUT_DIR = "/content/augmented"
OUTPUT_CSV = os.path.join(OUTPUT_DIR, "_annotations_augmented.csv")
AUG_PER_IMAGE = 5  # N√∫mero de veces que se aumentar√° cada imagen

os.makedirs(OUTPUT_DIR, exist_ok=True)

# === Aumentaciones ===
augment_pipeline = A.Compose([
    A.OneOf([
        A.HorizontalFlip(p=1.0),
        A.VerticalFlip(p=1.0),
        A.Rotate(limit=90, p=1.0),
        A.RandomBrightnessContrast(p=1.0),
        A.RandomGamma(p=1.0),
        A.RGBShift(p=1.0),
        A.HueSaturationValue(p=1.0)
    ], p=1.0),
    A.RandomSizedBBoxSafeCrop(width=500, height=500, p=0.9)
], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))

# === Leer CSV
df = pd.read_csv(CSV_PATH)

# === Agrupar por clase para balancear
augmented_rows = []

for class_name in df["class"].unique():
    class_group = df[df["class"] == class_name]
    grouped = class_group.groupby("filename")

    for filename, group in tqdm(grouped, desc=f"Aumentando clase: {class_name}"):
        image_path = os.path.join(INPUT_DIR, filename)
        image = cv2.imread(image_path)
        if image is None:
            continue

        bboxes = group[['xmin', 'ymin', 'xmax', 'ymax']].values
        labels = group['class'].tolist()

        for i in range(AUG_PER_IMAGE):
            try:
                aug = augment_pipeline(image=image, bboxes=bboxes, class_labels=labels)
            except:
                continue

            new_img = aug['image']
            new_bboxes = aug['bboxes']
            new_labels = aug['class_labels']

            if len(new_bboxes) == 0:
                continue

            new_filename = f"{os.path.splitext(filename)[0]}_{class_name}_aug{i}.jpg"
            new_path = os.path.join(OUTPUT_DIR, new_filename)
            cv2.imwrite(new_path, new_img)

            for j, box in enumerate(new_bboxes):
                x_min, y_min, x_max, y_max = map(int, box)
                augmented_rows.append({
                    'filename': new_filename,
                    'width': new_img.shape[1],
                    'height': new_img.shape[0],
                    'class': new_labels[j],
                    'xmin': x_min,
                    'ymin': y_min,
                    'xmax': x_max,
                    'ymax': y_max
                })

# === Guardar CSV
augmented_df = pd.DataFrame(augmented_rows)
augmented_df.to_csv(OUTPUT_CSV, index=False)

print("‚úÖ Aumentaci√≥n completada y CSV guardado:", OUTPUT_CSV)

import pandas as pd

# Ruta al nuevo CSV con aumentaciones
CSV_PATH = "/content/augmented/_annotations_augmented.csv"

# Leer el CSV
df_aug = pd.read_csv(CSV_PATH)

# Contar cu√°ntas anotaciones hay por clase
print("üìä Anotaciones totales por clase:")
print(df_aug["class"].value_counts())

# Contar cu√°ntas im√°genes √∫nicas hay por clase
print("\nüñºÔ∏è Im√°genes √∫nicas por clase:")
print(df_aug.groupby("class")["filename"].nunique())

!pip uninstall tensorflow -y
!pip install tensorflow==2.18.0

# ===========================================
# 0. GENERADOR DE DATOS: StrawberryGenerator
# ===========================================
import numpy as np
import cv2
import tensorflow as tf
import pandas as pd
import os

class StrawberryGenerator(tf.keras.utils.Sequence):
    def __init__(self, dataframe, input_dir, batch_size=16, img_size=224, max_boxes=9, shuffle=True):
        self.df = dataframe
        self.input_dir = input_dir
        self.batch_size = batch_size
        self.img_size = img_size
        self.max_boxes = max_boxes
        self.shuffle = shuffle
        self.files = self.df['filename'].unique()
        self.class_map = {'ripe': 0, 'semi ripe': 1, 'dead': 2}
        self.on_epoch_end()

    def __len__(self):
        return int(np.ceil(len(self.files) / self.batch_size))

    def __getitem__(self, idx):
        batch_files = self.files[idx * self.batch_size : (idx + 1) * self.batch_size]
        X, y_boxes, y_classes = [], [], []

        for file in batch_files:
            group = self.df[self.df['filename'] == file]
            img_path = os.path.join(self.input_dir, file)
            img = cv2.imread(img_path)
            if img is None:
                continue
            img = cv2.resize(img, (self.img_size, self.img_size))
            h, w = group['height'].iloc[0], group['width'].iloc[0]

            boxes = []
            classes = []
            for _, row in group.iterrows():
                x1 = row['xmin'] / w
                y1 = row['ymin'] / h
                x2 = row['xmax'] / w
                y2 = row['ymax'] / h
                boxes.append([x1, y1, x2, y2])
                classes.append(self.class_map[row['class']])

            while len(boxes) < self.max_boxes:
                boxes.append([0, 0, 0, 0])
                classes.append(-1)

            boxes = np.array(boxes[:self.max_boxes]).flatten().astype(np.float32)
            classes = np.array(classes[:self.max_boxes]).astype(np.int32)
            img = img.astype(np.float32) / 255.0

            X.append(img)
            y_boxes.append(boxes)
            y_classes.append(classes)

        return np.array(X), {'bboxes': np.array(y_boxes), 'class_probs': np.array(y_classes)}

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.files)

# ===========================================
# 1. ARQUITECTURA DEL MODELO ROBUSTO
# ===========================================
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input, Reshape
from tensorflow.keras.models import Model

IMG_SIZE = 224
MAX_BOXES = 9
NUM_CLASSES = 3

def build_robust_model():
    base_model = EfficientNetB0(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights='imagenet')
    base_model.trainable = False  # Fine-tuning despu√©s

    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(512, activation='relu')(x)
    x = Dropout(0.5)(x)

    bbox_output = Dense(MAX_BOXES * 4, activation='sigmoid', name='bboxes')(x)
    class_output = Dense(MAX_BOXES * NUM_CLASSES, activation='softmax')(x)
    class_output = Reshape((MAX_BOXES, NUM_CLASSES), name='class_probs')(class_output)

    return Model(inputs=base_model.input, outputs=[bbox_output, class_output])

model = build_robust_model()
model.summary()

# ===========================================
# 2. M√âTRICA Y P√âRDIDA PERSONALIZADA
# ===========================================
def true_box_accuracy(y_true, y_pred):
    mask = tf.not_equal(y_true, -1)
    y_true_masked = tf.cast(tf.boolean_mask(y_true, mask), tf.int32)
    y_pred_masked = tf.cast(tf.boolean_mask(tf.argmax(y_pred, axis=-1), mask), tf.int32)
    return tf.reduce_mean(tf.cast(tf.equal(y_true_masked, y_pred_masked), tf.float32))

def masked_sparse_categorical_crossentropy(y_true, y_pred):
    mask = tf.not_equal(y_true, -1)
    y_true_masked = tf.boolean_mask(y_true, mask)
    y_pred_masked = tf.boolean_mask(y_pred, mask)
    return tf.keras.losses.sparse_categorical_crossentropy(y_true_masked, y_pred_masked)

# ===========================================
# 3. COMPILACI√ìN DEL MODELO MEJORADO
# ===========================================
from tensorflow.keras.optimizers import AdamW

model.compile(
    optimizer=AdamW(learning_rate=1e-4, weight_decay=1e-5),
    loss={
        'bboxes': 'mse',
        'class_probs': masked_sparse_categorical_crossentropy
    },
    loss_weights={
        'bboxes': 1.0,
        'class_probs': 1.0
    },
    metrics={
        'class_probs': [true_box_accuracy, 'accuracy']
    }
)

# ===========================================
# 4. DEBUG VISUAL DEL GENERADOR
# ===========================================
def debug_dataset(generator, index=0):
    import matplotlib.pyplot as plt

    X, y = generator[index]
    img = (X[0] * 255).astype(np.uint8)
    h, w = img.shape[:2]
    boxes = y['bboxes'][0].reshape((9, 4))
    classes = y['class_probs'][0]
    label_map = ['ripe', 'semi ripe', 'dead']

    img_draw = img.copy()
    for i, box in enumerate(boxes):
        if np.allclose(box, 0):
            continue
        x1, y1, x2, y2 = box
        x1 = int(x1 * w)
        y1 = int(y1 * h)
        x2 = int(x2 * w)
        y2 = int(y2 * h)
        cls = classes[i]
        if cls == -1:
            continue
        probas = tf.nn.softmax(cls).numpy()
        class_id = np.argmax(probas)
        confidence = probas[class_id]
        if confidence < 0.5:
            continue
        label = f"{label_map[class_id]} ({confidence:.2f})"
        color = (0, 255, 0) if class_id == 0 else (255, 255, 0) if class_id == 1 else (255, 0, 0)
        cv2.rectangle(img_draw, (x1, y1), (x2, y2), color, 2)
        cv2.putText(img_draw, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

    plt.figure(figsize=(7,6))
    plt.imshow(cv2.cvtColor(img_draw, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.title("üîç Visualizaci√≥n de datos del generador")
    plt.show()

# ===========================================
# 5. DEFINICI√ìN DE GENERADORES + ENTRENAMIENTO
# ===========================================
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

INPUT_DIR = "/content/augmented"
CSV_PATH = os.path.join(INPUT_DIR, "_annotations_augmented.csv")
df = pd.read_csv(CSV_PATH)
train_df, val_df = train_test_split(df, test_size=0.15, random_state=42)

train_gen = StrawberryGenerator(train_df, input_dir=INPUT_DIR, batch_size=16)
val_gen = StrawberryGenerator(val_df, input_dir=INPUT_DIR, batch_size=16)

callbacks = [
    EarlyStopping(patience=8, restore_best_weights=True),
    ReduceLROnPlateau(patience=4, factor=0.5, min_lr=1e-6)
]

history = model.fit(train_gen, validation_data=val_gen, epochs=25, callbacks=callbacks)

# ===========================================
# 6. (OPCIONAL) FINE-TUNING POST ENTRENAMIENTO
# ===========================================
model.get_layer(index=1).trainable = True  # EfficientNetB0
model.compile(
    optimizer=AdamW(learning_rate=1e-5),
    loss={
        'bboxes': 'mse',
        'class_probs': masked_sparse_categorical_crossentropy
    },
    metrics={
        'class_probs': [true_box_accuracy, 'accuracy']
    }
)

history_fine = model.fit(train_gen, validation_data=val_gen, epochs=10, callbacks=callbacks)

# ===========================================
# 7. GUARDADO DEL MODELO ROBUSTO
# ===========================================
model.save("frutilla_detector_robusto_largo.h5", include_optimizer=False)
# ===========================================
from google.colab import files

# Descarga directa
files.download("frutilla_detector_robusto_largo.h5")

# ===========================================
# 6. PRUEBA DEL MODELO CARGADO
# ===========================================
import tensorflow as tf
import matplotlib.pyplot as plt
import cv2
import numpy as np
import os

model = tf.keras.models.load_model("frutilla_detector_clean.h5", compile=False)
image_index = 12340
folder = "/content/augmented"
label_map = ['ripe', 'semi ripe', 'dead']

# Verificar si la carpeta existe
if not os.path.exists(folder):
    raise FileNotFoundError(f"La carpeta '{folder}' no existe.")

# Obtener lista de archivos de imagen
files = sorted([f for f in os.listdir(folder) if f.endswith(('.jpg', '.png'))])

# Verificar que el √≠ndice est√© dentro del rango
if image_index >= len(files):
    raise IndexError(f"El √≠ndice {image_index} est√° fuera de rango. Solo hay {len(files)} im√°genes.")

# Procesar imagen
img_path = os.path.join(folder, files[image_index])
img = cv2.imread(img_path)
h_orig, w_orig = img.shape[:2]
img_resized = cv2.resize(img, (224, 224)) / 255.0
input_tensor = np.expand_dims(img_resized, axis=0)

# Realizar predicci√≥n
pred_boxes, pred_classes = model.predict(input_tensor)
pred_boxes = pred_boxes.reshape((9, 4))

# Verificar forma de pred_classes
if len(pred_classes.shape) == 3:
    pred_classes = np.argmax(pred_classes[0], axis=1)
else:
    pred_classes = np.argmax(pred_classes, axis=1)

# Dibujar resultados
for i in range(9):
    x1, y1, x2, y2 = pred_boxes[i]
    if (x2 - x1) < 0.01 or (y2 - y1) < 0.01:
        continue
    x1 = int(x1 * w_orig)
    y1 = int(y1 * h_orig)
    x2 = int(x2 * w_orig)
    y2 = int(y2 * h_orig)
    label = label_map[pred_classes[i]]
    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

# Mostrar imagen
plt.figure(figsize=(8, 6))
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.title(f"üìç Imagen #{image_index} ‚Üí {files[image_index]}")
plt.show()

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
with open('frutilla_detector.tflite', 'wb') as f:
    f.write(converter.convert())

files.download ('frutilla_detector.tflite')

import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import os

# === Clases del modelo ===
CLASSES = ["ripe", "semi ripe", "dead"]

# === Rutas ===
MODEL_PATH = "frutilla_detector_clean.h5"  # ‚Üê Cambia si es otro nombre
IMAGE_PATH = "/content/frutilla.png"          # ‚Üê Cambia por tu imagen

# === Verificar archivos ===
if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"‚ùå Modelo no encontrado: {MODEL_PATH}")
if not os.path.exists(IMAGE_PATH):
    raise FileNotFoundError(f"‚ùå Imagen no encontrada: {IMAGE_PATH}")

# === Cargar modelo Keras (.h5) ===
model = tf.keras.models.load_model(MODEL_PATH, compile=False)

# === Leer y preprocesar imagen ===
img = cv2.imread(IMAGE_PATH)
h_orig, w_orig = img.shape[:2]
img_resized = cv2.resize(img, (224, 224)).astype(np.float32) / 255.0
input_tensor = np.expand_dims(img_resized, axis=0)

# === Inferencia ===
pred_boxes, pred_classes = model.predict(input_tensor)

# === Procesar salidas ===
pred_boxes = pred_boxes.reshape((-1, 4))

if len(pred_classes.shape) == 3:
    probs = pred_classes[0]
    pred_classes = np.argmax(probs, axis=1)
else:
    probs = pred_classes
    pred_classes = np.argmax(probs, axis=1)

# === Conteo y confianza ===
conteo = {cls: 0 for cls in CLASSES}
confianza_total = {cls: 0.0 for cls in CLASSES}

# === Dibujar detecciones ===
for i, box in enumerate(pred_boxes):
    if len(box) != 4:
        continue
    x1, y1, x2, y2 = box
    if (x2 - x1) < 0.01 or (y2 - y1) < 0.01:
        continue

    x1 = int(x1 * w_orig)
    y1 = int(y1 * h_orig)
    x2 = int(x2 * w_orig)
    y2 = int(y2 * h_orig)

    label = CLASSES[pred_classes[i]]
    conf = probs[i][pred_classes[i]] if probs.ndim == 2 else 1.0

    conteo[label] += 1
    confianza_total[label] += conf

    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    cv2.putText(img, f"{label} {conf:.2f}", (x1, y1 - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

# === Mostrar imagen con resultados ===
plt.figure(figsize=(10, 8))
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.title("üß† Detecci√≥n con modelo .h5")
plt.show()

# === Mostrar resumen ===
print("\n‚úÖ Resultado:")
for cls in CLASSES:
    total = conteo[cls]
    avg_conf = confianza_total[cls] / total if total > 0 else 0
    print(f"  - {cls}: {total} detecciones, confianza promedio {avg_conf:.3f}")

# En el entorno donde se entren√≥ el modelo
model = tf.keras.models.load_model("frutilla_detector_clean.h5")
model.save("frutilla_detector_clean.keras", save_format="keras")

import os
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# === Clases del modelo ===
CLASSES = ["ripe", "semi ripe", "dead", "background"]

# === Ruta del modelo y carpeta con im√°genes ===
MODEL_PATH = "frutilla_detector_clean.h5"
TEST_IMAGES_DIR = "/content/augmented"  # Aseg√∫rate de tener esta carpeta y que contenga im√°genes

# === Cargar modelo Keras ===
model = tf.keras.models.load_model(MODEL_PATH, compile=False)

# === Variables para etiquetas ===
y_true = []
y_pred = []

# === Clasificaci√≥n de im√°genes una por una ===
for file in os.listdir(TEST_IMAGES_DIR):
    if file.lower().endswith((".jpg", ".png")):
        # Deducir la etiqueta verdadera a partir del nombre del archivo
        true_label = None
        for cls in CLASSES:
            if cls.replace(" ", "").lower() in file.lower():
                true_label = cls
                break
        if true_label is None:
            continue  # saltar si no coincide

        img_path = os.path.join(TEST_IMAGES_DIR, file)
        img = tf.keras.utils.load_img(img_path, target_size=(224, 224))
        img_array = tf.keras.utils.img_to_array(img) / 255.0
        input_tensor = np.expand_dims(img_array, axis=0)

        # Predicci√≥n
        pred = model.predict(input_tensor)[0]
        pred_label = CLASSES[np.argmax(pred)]

        y_true.append(true_label)
        y_pred.append(pred_label)

# === Matriz de confusi√≥n ===
cm = confusion_matrix(y_true, y_pred, labels=CLASSES)
df_cm = pd.DataFrame(cm, index=CLASSES, columns=CLASSES)

plt.figure(figsize=(8, 6))
sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("True")
plt.ylabel("Predicted")
plt.tight_layout()
plt.show()
